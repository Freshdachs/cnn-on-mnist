{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying handwritten digits with Convolutional Neural Networks\n",
    "### using Tensorflow\n",
    "useful links:\n",
    "- https://www.tensorflow.org/versions/r0.11/tutorials/deep_cnn/index.html\n",
    "- https://martin-thoma.com/tensor-flow-quick/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some generic Code for setting up an interactive tensorflow session and the mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functools import *\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#onehot means a vector is 1 in a single dimension and 0 in every other\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_inputs = 784\n",
    "n_classes = 10\n",
    "batch_size = 50\n",
    "\n",
    "x = tf.placeholder('float', [None, n_inputs])\n",
    "y = tf.placeholder('float',[None, 10])\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, k=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, k, k, 1] , padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_neural_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    \n",
    "    # Pooling 1\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    \n",
    "    # Pooling 2\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_and_test_conv_neural_net(x, y, weights, biases, epochs = 1):\n",
    "    \n",
    "    pred = conv_neural_net(x, weights, biases)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\n",
    "    opt = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        for e in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([opt, cost], \n",
    "                                feed_dict = {x:epoch_x, y:epoch_y})\n",
    "                epoch_loss = epoch_loss + c\n",
    "            print('Epoch ' + str(e+1) + ' out of ' + \n",
    "            str(epochs) + ' / Loss: ' + str(epoch_loss))\n",
    "            \n",
    "            correct = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "            print('Accuracy: ' + str(accuracy.eval({x:mnist.test.images, \n",
    "                                                y:mnist.test.labels})))\n",
    "\n",
    "        print( 'Training finished!'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 15 / Loss: 2127578.55677\n",
      "Accuracy: 0.9423\n",
      "Epoch 2 out of 15 / Loss: 445672.989081\n",
      "Accuracy: 0.9487\n",
      "Epoch 3 out of 15 / Loss: 265236.888775\n",
      "Accuracy: 0.9707\n",
      "Epoch 4 out of 15 / Loss: 163206.372727\n",
      "Accuracy: 0.9733\n",
      "Epoch 5 out of 15 / Loss: 112788.947389\n",
      "Accuracy: 0.9716\n",
      "Epoch 6 out of 15 / Loss: 79616.1067975\n",
      "Accuracy: 0.9753\n",
      "Epoch 7 out of 15 / Loss: 58562.9584\n",
      "Accuracy: 0.9692\n",
      "Epoch 8 out of 15 / Loss: 43712.7670352\n",
      "Accuracy: 0.9783\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-886254e3a1ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_and_test_conv_neural_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Time: '\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ebc29272e5d0>\u001b[0m in \u001b[0;36mtrain_and_test_conv_neural_net\u001b[0;34m(x, y, weights, biases, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mepoch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 _, c = sess.run([opt, cost], \n\u001b[0;32m---> 14\u001b[0;31m                                 feed_dict = {x:epoch_x, y:epoch_y})\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             print('Epoch ' + str(e+1) + ' out of ' + \n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train_and_test_conv_neural_net(x, y, weights, biases, 15)\n",
    "print( 'Time: ' +  str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 48])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 48, 48])),\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 48, 32])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*32, 1024])),\n",
    "    'wd2': tf.Variable(tf.random_normal([1024,512])),\n",
    "    'out': tf.Variable(tf.random_normal([512, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([48])),\n",
    "    'bc2': tf.Variable(tf.random_normal([48])),\n",
    "    'bc3': tf.Variable(tf.random_normal([32])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'bd2': tf.Variable(tf.random_normal([512])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def conv_neural_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], k=1)\n",
    "    \n",
    "    # Pooling 1\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], k=1)\n",
    "    \n",
    "    # Pooling 2\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Convolution 2\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'], k=1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    # Predictions\n",
    "    out = tf.add(tf.matmul(fc2, weights['out']), biases['out'])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1 out of 15 / Loss: 468610514.509\n",
    "Accuracy: 0.9451\n",
    "\n",
    "Epoch 2 out of 15 / Loss: 95684529.7457\n",
    "Accuracy: 0.9519\n",
    "\n",
    "Epoch 3 out of 15 / Loss: 47215840.6904\n",
    "Accuracy: 0.9607\n",
    "\n",
    "Epoch 4 out of 15 / Loss: 32338930.3717\n",
    "Accuracy: 0.9625\n",
    "\n",
    "Epoch 5 out of 15 / Loss: 23484511.0364\n",
    "Accuracy: 0.9688\n",
    "\n",
    "Epoch 6 out of 15 / Loss: 17932300.7021\n",
    "Accuracy: 0.9704\n",
    "\n",
    "Epoch 7 out of 15 / Loss: 13503283.2412\n",
    "Accuracy: 0.9712\n",
    "\n",
    "Epoch 8 out of 15 / Loss: 10075762.2565\n",
    "Accuracy: 0.974\n",
    "\n",
    "Epoch 9 out of 15 / Loss: 8688486.11646\n",
    "Accuracy: 0.9795\n",
    "\n",
    "Epoch 10 out of 15 / Loss: 7702904.45678\n",
    "Accuracy: 0.9766\n",
    "\n",
    "Epoch 11 out of 15 / Loss: 7166355.99678\n",
    "Accuracy: 0.9769\n",
    "\n",
    "Epoch 12 out of 15 / Loss: 5661994.87721\n",
    "Accuracy: 0.9767\n",
    "\n",
    "Epoch 13 out of 15 / Loss: 5315591.25652\n",
    "Accuracy: 0.9794\n",
    "\n",
    "Epoch 14 out of 15 / Loss: 4978734.87103\n",
    "Accuracy: 0.982\n",
    "\n",
    "Epoch 15 out of 15 / Loss: 4567343.04259\n",
    "Accuracy: 0.9764\n",
    "\n",
    "Training finished!\n",
    "Time: 3057.45236683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "def conv_neural_net(x, weights, biases):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    \n",
    "    # Pooling 1\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    \n",
    "    # Pooling 2\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1 out of 15 / Loss: 2048269.96789\n",
    "Accuracy: 0.9521\n",
    "\n",
    "Epoch 2 out of 15 / Loss: 416296.553819\n",
    "Accuracy: 0.9562\n",
    "\n",
    "Epoch 3 out of 15 / Loss: 230842.755202\n",
    "Accuracy: 0.9515\n",
    "\n",
    "Epoch 4 out of 15 / Loss: 149993.567395\n",
    "Accuracy: 0.9741\n",
    "\n",
    "Epoch 5 out of 15 / Loss: 104185.315256\n",
    "Accuracy: 0.9787\n",
    "\n",
    "Epoch 6 out of 15 / Loss: 65479.1788944\n",
    "Accuracy: 0.9785\n",
    "\n",
    "Epoch 7 out of 15 / Loss: 56342.0501099\n",
    "Accuracy: 0.9819\n",
    "\n",
    "Epoch 8 out of 15 / Loss: 37191.8697067\n",
    "Accuracy: 0.9757\n",
    "\n",
    "Epoch 9 out of 15 / Loss: 31626.6323467\n",
    "Accuracy: 0.9802\n",
    "\n",
    "Epoch 10 out of 15 / Loss: 26357.9734757\n",
    "Accuracy: 0.9839\n",
    "\n",
    "Epoch 11 out of 15 / Loss: 19355.0131723\n",
    "Accuracy: 0.9817\n",
    "\n",
    "Epoch 12 out of 15 / Loss: 17152.4177485\n",
    "Accuracy: 0.9849\n",
    "\n",
    "Epoch 13 out of 15 / Loss: 18811.924521\n",
    "Accuracy: 0.9827\n",
    "\n",
    "Epoch 14 out of 15 / Loss: 11879.7064547\n",
    "Accuracy: 0.9848\n",
    "\n",
    "Epoch 15 out of 15 / Loss: 13809.3100464\n",
    "Accuracy: 0.9799\n",
    "\n",
    "Training finished!\n",
    "Time: 2197.68839502"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
